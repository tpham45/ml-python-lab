{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "# Lifestyle and Health Risk Data Analysis\n",
    "\n",
    "Date: 11/19/2025\n",
    "\n",
    "Team Members:\n",
    "- Karrie Butcher\n",
    "- Nicko Lomelin\n",
    "- Thanh Tuan Pham\n",
    "\n",
    "dataset: https://www.kaggle.com/datasets/miadul/lifestyle-and-health-risk-prediction \n",
    "\n",
    "The dataset is designed for predicting an individual's general health risk (classified as 'high' or 'low') based on a combination of lifestyle metrics (like exercise, sleep, sugar intake, smoking, and alcohol consumption) and physical/demographic attributes (age, weight, height, BMI, marital status, and profession). The primary business or public health value of building a predictive model on this data is to identify high-risk individuals proactively, allowing for targeted and timely health interventions, personalized risk communication, and more efficient allocation of healthcare resources to potentially prevent the onset of serious health issues.\n",
    "\n",
    "Prediction Task: **Binary Classification of Health Risk**\n",
    "\n",
    "We will build a model to predict the health_risk (the target variable) as either 'high' or 'low' based on the other features.\n",
    "\n",
    "---\n",
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (5000, 12)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   age           5000 non-null   int64  \n",
      " 1   weight        5000 non-null   int64  \n",
      " 2   height        5000 non-null   int64  \n",
      " 3   exercise      5000 non-null   object \n",
      " 4   sleep         5000 non-null   float64\n",
      " 5   sugar_intake  5000 non-null   object \n",
      " 6   smoking       5000 non-null   object \n",
      " 7   alcohol       5000 non-null   object \n",
      " 8   married       5000 non-null   object \n",
      " 9   profession    5000 non-null   object \n",
      " 10  bmi           5000 non-null   float64\n",
      " 11  health_risk   5000 non-null   object \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "file_path = Path.home() / \"Downloads\" / \"Lifestyle_and_Health_Risk_Prediction_Synthetic_Dataset.csv\"\n",
    "\n",
    "# load into pandas\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Initial shape:\", df.shape)\n",
    "df.head()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping height/weight: (5000, 9)\n",
      "--- Processed Data Shapes ---\n",
      "Train shape: (3500, 25)\n",
      "Validation shape: (750, 25)\n",
      "Test shape: (750, 25)\n",
      "\n",
      "--- Final Train Sample (Processed) ---\n",
      "           age     sleep       bmi  exercise_high  exercise_low  \\\n",
      "2528 -1.334679 -0.750091 -1.530895            0.0           0.0   \n",
      "1172 -0.998141  0.431671  0.378948            0.0           1.0   \n",
      "2292  0.291923 -2.209913 -0.290105            0.0           1.0   \n",
      "2535  0.852820 -0.889121  0.719557            0.0           0.0   \n",
      "3962 -0.829872 -0.680575 -1.226780            0.0           0.0   \n",
      "\n",
      "      exercise_medium  exercise_none  sugar_intake_high  sugar_intake_low  \\\n",
      "2528              1.0            0.0                1.0               0.0   \n",
      "1172              0.0            0.0                1.0               0.0   \n",
      "2292              0.0            0.0                0.0               1.0   \n",
      "2535              0.0            1.0                0.0               0.0   \n",
      "3962              1.0            0.0                0.0               1.0   \n",
      "\n",
      "      sugar_intake_medium  ...  married_yes  profession_artist  \\\n",
      "2528                  0.0  ...          1.0                0.0   \n",
      "1172                  0.0  ...          0.0                0.0   \n",
      "2292                  0.0  ...          0.0                0.0   \n",
      "2535                  1.0  ...          1.0                0.0   \n",
      "3962                  0.0  ...          1.0                0.0   \n",
      "\n",
      "      profession_doctor  profession_driver  profession_engineer  \\\n",
      "2528                0.0                0.0                  0.0   \n",
      "1172                0.0                0.0                  0.0   \n",
      "2292                0.0                0.0                  0.0   \n",
      "2535                0.0                0.0                  0.0   \n",
      "3962                0.0                0.0                  1.0   \n",
      "\n",
      "      profession_farmer  profession_office_worker  profession_student  \\\n",
      "2528                0.0                       0.0                 0.0   \n",
      "1172                0.0                       1.0                 0.0   \n",
      "2292                0.0                       0.0                 1.0   \n",
      "2535                0.0                       0.0                 1.0   \n",
      "3962                0.0                       0.0                 0.0   \n",
      "\n",
      "      profession_teacher  health_risk_encoded  \n",
      "2528                 1.0                    0  \n",
      "1172                 0.0                    1  \n",
      "2292                 0.0                    1  \n",
      "2535                 0.0                    1  \n",
      "3962                 0.0                    0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "--- Final Validation Sample (Processed) ---\n",
      "           age     sleep       bmi  exercise_high  exercise_low  \\\n",
      "3417  1.581987 -1.306213  0.281632            0.0           0.0   \n",
      "870  -0.268974  0.570701  0.756051            0.0           1.0   \n",
      "3322 -0.717692  0.640217 -0.314434            0.0           0.0   \n",
      "4412  0.516282  0.501186 -1.421414            0.0           0.0   \n",
      "4827  0.067564  1.265855  0.245138            0.0           1.0   \n",
      "\n",
      "      exercise_medium  exercise_none  sugar_intake_high  sugar_intake_low  \\\n",
      "3417              0.0            1.0                0.0               0.0   \n",
      "870               0.0            0.0                0.0               0.0   \n",
      "3322              1.0            0.0                0.0               1.0   \n",
      "4412              1.0            0.0                0.0               1.0   \n",
      "4827              0.0            0.0                0.0               1.0   \n",
      "\n",
      "      sugar_intake_medium  ...  married_yes  profession_artist  \\\n",
      "3417                  1.0  ...          0.0                1.0   \n",
      "870                   1.0  ...          0.0                0.0   \n",
      "3322                  0.0  ...          1.0                0.0   \n",
      "4412                  0.0  ...          0.0                1.0   \n",
      "4827                  0.0  ...          1.0                0.0   \n",
      "\n",
      "      profession_doctor  profession_driver  profession_engineer  \\\n",
      "3417                0.0                0.0                  0.0   \n",
      "870                 0.0                0.0                  0.0   \n",
      "3322                0.0                0.0                  0.0   \n",
      "4412                0.0                0.0                  0.0   \n",
      "4827                0.0                1.0                  0.0   \n",
      "\n",
      "      profession_farmer  profession_office_worker  profession_student  \\\n",
      "3417                0.0                       0.0                 0.0   \n",
      "870                 1.0                       0.0                 0.0   \n",
      "3322                0.0                       0.0                 1.0   \n",
      "4412                0.0                       0.0                 0.0   \n",
      "4827                0.0                       0.0                 0.0   \n",
      "\n",
      "      profession_teacher  health_risk_encoded  \n",
      "3417                 0.0                    1  \n",
      "870                  0.0                    1  \n",
      "3322                 0.0                    0  \n",
      "4412                 0.0                    1  \n",
      "4827                 0.0                    1  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encode the target variable\n",
    "df['health_risk_encoded'] = df['health_risk'].apply(lambda x: 1 if x == 'high' else 0)\n",
    "X = df.drop(columns=['health_risk', 'health_risk_encoded'])\n",
    "y = df['health_risk_encoded']\n",
    "\n",
    "# We keep 'bmi' and drop the 'height' and 'weight' it was calculated from.\n",
    "X = X.drop(columns=['height', 'weight'])\n",
    "print(f\"Shape after dropping height/weight: {X.shape}\")\n",
    "\n",
    "# Define feature groups\n",
    "NUMERICAL_FEATURES = ['age','sleep', 'bmi']\n",
    "CATEGORICAL_FEATURES = ['exercise', 'sugar_intake', 'smoking', 'alcohol', 'married', 'profession']\n",
    "\n",
    "# --- 2. Stratified Data Split ---\n",
    "# Split into Train (70%), and a temporary set (30%) - Stratified\n",
    "X_train_raw, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split the temporary set into Validation (15%) and Test (15%) - Stratified\n",
    "X_val_raw, X_test_raw, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# --- 3. Preprocessing: Scaling Numerical Features ---\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw[NUMERICAL_FEATURES])\n",
    "\n",
    "X_train_num_scaled = scaler.transform(X_train_raw[NUMERICAL_FEATURES])\n",
    "X_val_num_scaled = scaler.transform(X_val_raw[NUMERICAL_FEATURES])\n",
    "X_test_num_scaled = scaler.transform(X_test_raw[NUMERICAL_FEATURES])\n",
    "\n",
    "# --- 4. Final DataFrames for Wide and Deep Input ---\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "ohe.fit(X_train_raw[CATEGORICAL_FEATURES])\n",
    "\n",
    "X_train_cat_ohe = ohe.transform(X_train_raw[CATEGORICAL_FEATURES])\n",
    "X_val_cat_ohe = ohe.transform(X_val_raw[CATEGORICAL_FEATURES])\n",
    "X_test_cat_ohe = ohe.transform(X_test_raw[CATEGORICAL_FEATURES])\n",
    "\n",
    "ohe_feature_names = ohe.get_feature_names_out(CATEGORICAL_FEATURES)\n",
    "\n",
    "\n",
    "# Combine scaled numerical and one-hot categorical features for a fully-processed X\n",
    "# We use the original indices to ensure correct alignment\n",
    "X_train_processed = pd.concat([\n",
    "    pd.DataFrame(X_train_num_scaled, columns=NUMERICAL_FEATURES, index=X_train_raw.index),\n",
    "    pd.DataFrame(X_train_cat_ohe, columns=ohe_feature_names, index=X_train_raw.index)\n",
    "], axis=1)\n",
    "\n",
    "X_val_processed = pd.concat([\n",
    "    pd.DataFrame(X_val_num_scaled, columns=NUMERICAL_FEATURES, index=X_val_raw.index),\n",
    "    pd.DataFrame(X_val_cat_ohe, columns=ohe_feature_names, index=X_val_raw.index)\n",
    "], axis=1)\n",
    "\n",
    "X_test_processed = pd.concat([\n",
    "    pd.DataFrame(X_test_num_scaled, columns=NUMERICAL_FEATURES, index=X_test_raw.index),\n",
    "    pd.DataFrame(X_test_cat_ohe, columns=ohe_feature_names, index=X_test_raw.index)\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "# --- 7. Final DataFrames for Model Input ---\n",
    "# These are the final, complete dataframes your model will use\n",
    "train_df = pd.concat([X_train_processed, y_train], axis=1)\n",
    "val_df = pd.concat([X_val_processed, y_val], axis=1)\n",
    "test_df = pd.concat([X_test_processed, y_test], axis=1)\n",
    "\n",
    "print(\"--- Processed Data Shapes ---\")\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Validation shape:\", val_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "print(\"\\n--- Final Train Sample (Processed) ---\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\n--- Final Validation Sample (Processed) ---\")\n",
    "print(val_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description of Final Prepared Dataset**\n",
    "\n",
    "The final dataset for classification is defined across three stratified sets: Training (3,500 rows), Validation (750 rows), and Test (750 rows). The original variables height and weight were removed to prevent multicollinearity, resulting in 24 final features for the model.The final variables are represented as follows:Target Variable: A newly created integer variable, health_risk_encoded, which is the class variable for binary classification. It is encoded as $\\mathbf{1}$ for 'high risk' and $\\mathbf{0}$ for 'low risk'.Numerical Features: The three numerical features (age, sleep, bmi) have been Standard Scaled (Z-score normalization). This process centers the data around a mean of $0$ with a standard deviation of $1$, ensuring they are appropriately weighted for the deep neural network component.Categorical Features: The six categorical features (exercise, sugar_intake, smoking, alcohol, married, profession) have been transformed using One-Hot Encoding (via Scikit-learn). They are represented as $\\mathbf{21}$ binary columns within the pandas DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "### **1.2 Identifying and Justifying Cross-Product Features** \n",
    "\n",
    "\n",
    "We identified the following three feature crosses, which capture critical interactions influencing health:\n",
    "\n",
    "| Cross-Product Feature | Component Features |  Justification |\n",
    "| :--- | :--- | :--- |\n",
    "| **`smoking` $\\times$ `alcohol`** | `smoking` and `alcohol` | This cross captures the **multiplicative risk** associated with combining these two high-risk behaviors. Medical science confirms that combined tobacco and alcohol use dramatically amplifies the risk of several cancers and cardiovascular issues, a risk far greater than the sum of their individual effects. The cross-feature allows the model to precisely memorize the severe risk of the 'Yes' $\\times$ 'Yes' combination. |\n",
    "| **`exercise` $\\times$ `sugar_intake`** | `exercise` and `sugar_intake` | This combination represents a key aspect of an individual's **Metabolic Lifestyle and Energy Balance**. The specific interaction, such as \"Low Exercise $\\times$ High Sugar Intake,\" often defines a particularly high-risk metabolic state. Treating these factors independently in the wide path would miss the powerful predictive signal of this specific, highly detrimental combination. |\n",
    "| **`profession` $\\times$ `married`** | `profession` and `married` | This serves as a **proxy for Socioeconomic Stress and Social Support**. The health risk inherent to a specific job is often moderated by external social factors. For example, the stress of a high-demand profession might be mitigated by a stable support system (being 'married'). The cross allows the model to learn and memorize job-specific risk profiles contingent on this major social factor. |\n",
    "\n",
    "#### **Features Not Crossed**\n",
    "\n",
    "The **numerical features** (`age`,`sleep`, `bmi`) should **not be crossed**. \n",
    "\n",
    "This is because:\n",
    "1.  Crossing continuous features creates an intractable number of categories.\n",
    "2.  Learning complex, non-linear interactions between these continuous variables is the primary function of the **Deep component**, which uses hidden layers and activation functions for generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### **1.3 Chosen Evaluation Metric(s)**\n",
    "\n",
    "The chosen prediction task is a binary classification of health risk, where the data is **imbalanced** (approximately $70\\%$ 'high risk' and $30\\%$ 'low risk'). Therefore, **Accuracy** is an unreliable metric, as a model could achieve $70\\%$ accuracy simply by predicting 'high risk' every time.\n",
    "\n",
    "We will use two metrics that are more appropriate for this critical public health task: **Recall** as the primary focus, and the **Area Under the ROC Curve (AUC-ROC)** as the secondary measure.\n",
    "\n",
    "### **Primary Metric: Recall (Sensitivity) for the Positive Class (High Risk = 1)**\n",
    "\n",
    "The formula for Recall is:\n",
    "$$\\text{Recall} = \\frac{\\text{True Positives (TP)}}{\\text{True Positives (TP)} + \\text{False Negatives (FN)}}$$\n",
    "\n",
    "#### **Justification and Business Case**\n",
    "\n",
    "The business objective of a health risk prediction model is **proactive intervention**; identifying individuals who require preventative care. In this context, the most severe and costly error is the **False Negative (FN)**, which occurs when the model predicts a person is 'low risk' (0) when they are *truly* 'high risk' (1).\n",
    "\n",
    "* **Consequence of FN**: A missed high-risk patient receives no intervention, which can lead to the progression of severe, preventable illness, resulting in high future healthcare costs and patient harm.\n",
    "\n",
    "* **Recall's Role**: **Recall** directly measures the proportion of *all actual high-risk individuals* that the model successfully identifies. By maximizing Recall, we are minimizing the devastating impact of False Negatives. This aligns perfectly with the public health mandate to **not miss a high-risk patient**, making it the most appropriate metric for this life-critical task.\n",
    "\n",
    "### **Secondary Metric: Area Under the ROC Curve (AUC-ROC)**\n",
    "\n",
    "The AUC-ROC measures the overall ability of the model to distinguish between the two classes.\n",
    "\n",
    "#### **Justification**\n",
    "\n",
    "The AUC-ROC is superior to accuracy for this task because it is **robust to class imbalance**. It evaluates the model's performance across **all possible classification thresholds**. This gives a single, reliable value that represents the model's general discriminatory power. We will use AUC-ROC to fairly compare the overall generalization strength of the **Wide and Deep Network** against the **Deep-Only Network**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### **1.4. Chosen Method: Stratified Train/Validation/Test Split**\n",
    "\n",
    "We have divided the data into three separate sets:\n",
    "\n",
    "1.  **Training Set (70%):** Used for fitting the model weights.\n",
    "\n",
    "2.  **Validation Set (15%):** Used for tuning hyper-parameters and deciding when to stop training.\n",
    "\n",
    "3.  **Test Set (15%):** Reserved for the final, unbiased evaluation of the model's performance.\n",
    "\n",
    "The key technique applied to this split is **Stratification**.\n",
    "\n",
    "### **Justification**\n",
    "\n",
    "Stratified splitting ensures that the original proportion of the target classes ('high risk' and 'low risk') is maintained across the training, validation, and test sets.\n",
    "\n",
    "* **Handling Imbalance:** Since the dataset is imbalanced ($\\approx 70\\%$ 'high risk' and $30\\%$ 'low risk'), non-stratified splitting could, by chance, lead to a test set with a significantly different class ratio (e.g., $90\\%$ 'high risk'). Stratification prevents this random variation, guaranteeing that the performance metrics (especially Recall and AUC-ROC) reported on the Test set are a more **reliable and realistic** estimate of the model's generalization performance on data from the same population.\n",
    "\n",
    "### **Mirroring Real-World Practice**\n",
    "\n",
    "This single, fixed split into Training, Validation, and Test sets is the most appropriate method because it **realistically mirrors the typical production deployment lifecycle** of a deep learning model:\n",
    "\n",
    "1.  **Development and Tuning:** An organization uses the **Training** and **Validation** sets to iterate on model design and tune hyper-parameters.\n",
    "\n",
    "2.  **Final Deployment Decision:** Once the model performs satisfactorily on the Validation set, it is evaluated **one time** on the unseen **Test** set to get an unbiased measure of its expected performance.\n",
    "\n",
    "3.  **Deployment:** The final, chosen model is then deployed to handle new, incoming data.\n",
    "\n",
    "Methods like 10-fold cross-validation, while great for small datasets or estimating model stability, are less common for large-scale deep learning deployment. They involve training ten different models, which is computationally expensive and complex for productionizing a single system. Our chosen method provides a direct, efficient, and robust simulation of the real-world usage of a single, deployed algorithm.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exceptional Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
